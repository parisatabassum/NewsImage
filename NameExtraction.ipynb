{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e8f30b",
   "metadata": {},
   "source": [
    "## Name Extraction \n",
    "Extract person's names from article title using Stanford NE\\\n",
    "save the extracted person's name into txt files on disk for later use\n",
    "\n",
    "## Face - Name Matching Dataset Creation\n",
    "### I create an subset (face-name matching dataset) from the given image dataset. This dataset is only used for face-name matching\n",
    "\\\n",
    "Create the image folder for each extracted name, and copy paired images to the name folder\\\n",
    "To reduce processing time, I apply several face detection algorithms on all images in both training dataset and test dataset. An image is removed from face-name matching dataset if no faces are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "983bb73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_name(classified_text):\n",
    "    i=0\n",
    "    name_list=[]\n",
    "    while i < len(classified_text)-1:\n",
    "        if classified_text[i][1] == 'PERSON':\n",
    "            name = classified_text[i][0]\n",
    "            if classified_text[i+1][1]=='PERSON':\n",
    "                name+=\" \"+classified_text[i+1][0]\n",
    "                i+=1 \n",
    "            name_list.append(name)\n",
    "        i+=1\n",
    "    if i == len(classified_text)-1 and classified_text[i][1] == 'PERSON':\n",
    "        name_list.append(classified_text[i][0])\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "java_path = r\"C:\\Users\\yuxia\\Documents\\java-se-8u41-ri\\bin\\java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "st = StanfordNERTagger(r'C:\\Users\\yuxia\\Downloads\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\\classifiers\\english.all.3class.distsim.crf.ser.gz',\n",
    "                       r'C:\\Users\\yuxia\\Downloads\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\\stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "a_file = open(r\"C:\\Users\\yuxia\\Downloads\\trans-test.txt\")\n",
    "next(a_file)\n",
    "cnt=0\n",
    "name_list=[]\n",
    "for line in a_file:\n",
    "    tokenized_text = word_tokenize(line)\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    names=concat_name(classified_text)\n",
    "    if len(names) > 0:\n",
    "        print(names)\n",
    "        cnt+=1\n",
    "    name_list.append(names)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f160a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_title_eng (orig_file, title_eng_file, output_file):\n",
    "    lines = [line.strip() for line in open(orig_file, 'r', encoding=\"utf-8\")]\n",
    "    titles_eng = [line.strip() for line in open(title_eng_file, 'r', encoding=\"utf-8\")]\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        for i in range(len(lines)):\n",
    "            title_eng=titles_eng[i].rstrip(\"\\n\")\n",
    "            segs=lines[i].strip(\"\\n\").split(\",\")\n",
    "            the_file.write(segs[0]+\"\\t\"+segs[1]+\"\\t\"+segs[2]+'\\t'+title_eng+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "86971ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng(\"train_01.csv\", \"trans-01.txt\", 'title_01_title_eng.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31e7a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng(\"train_02.csv\", \"trans-02.txt\",'title_02_title_eng.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4dc76ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng(\"train_03.csv\", \"trans-03.txt\",'title_03_title_eng.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6af08e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "java_path = r\"C:\\Users\\yuxia\\Documents\\java-se-8u41-ri\\bin\\java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "st = StanfordNERTagger(r'C:\\Users\\yuxia\\Downloads\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\\classifiers\\english.all.3class.distsim.crf.ser.gz',\n",
    "                       r'C:\\Users\\yuxia\\Downloads\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\\stanford-ner.jar',\n",
    "                       encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "84640cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_title_name(tr_file, output_file):\n",
    "    a_file = open(tr_file, encoding=\"utf8\")\n",
    "    next(a_file)\n",
    "    cnt=0\n",
    "    name_list=[]\n",
    "    header=\"img_id\"+\"\\t\"+\"img_name\"+\"\\t\"+\"title\"+\"\\t\"+\"title_eng\"+\"\\t\"+\"title_names\"\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        for line in a_file:\n",
    "            title_eng=line.split(\"\\t\")[3]\n",
    "            tokenized_text = word_tokenize(title_eng)\n",
    "            classified_text = st.tag(tokenized_text)\n",
    "            names=concat_name(classified_text)\n",
    "            if len(names)>0:\n",
    "                names_str = ','.join(names)\n",
    "                print(names_str)\n",
    "                new_line=line.strip(\"\\n\")+\"\\t\"+names_str+\"\\n\"\n",
    "                cnt+=1\n",
    "            else:\n",
    "                new_line=line.strip(\"\\n\")+\"\\t \"+\"\\n\"\n",
    "            the_file.write(new_line)\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd71c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_title_name(\"title_02_title_eng.tsv\", \"title_02_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18908c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_title_name(\"title_03_title_eng.tsv\", \"title_03_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "14acaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv(\"title_03_title_eng_name - Copy.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7b8700bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>129437.jpg</th>\n",
       "      <th>dpa-polizist-vor-polizeiauto.jpg</th>\n",
       "      <th>Polizei-Azubi erschießt mutmaßlich Mit-Auszubildenden</th>\n",
       "      <th>Police Azubi shoots alleged with-apprentices</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129439.jpg</td>\n",
       "      <td>ali-t--280219.jpg</td>\n",
       "      <td>Hauptverdächtiger in Türkei gefasst – und wied...</td>\n",
       "      <td>Main suspect in Turkey - and released again</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129440.jpg</td>\n",
       "      <td>kita-symbol.jpg</td>\n",
       "      <td>Rhein-Erft-Kreis stoppt Kita-Bonus für städtis...</td>\n",
       "      <td>Rhine-Erft-Kreis Stops Kita bonus for urban em...</td>\n",
       "      <td>Kita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129442.jpg</td>\n",
       "      <td>bahnsteig-station-dom-hauptbahnhof.jpg</td>\n",
       "      <td>KVB-Fahrgastzahlen sind Grund zur Freude und S...</td>\n",
       "      <td>KVB passenger numbers are reason for joy and c...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129443.jpg</td>\n",
       "      <td>annegret-kramp-karrenbaur-cdu.jpg</td>\n",
       "      <td>„Wir wollen eine Rüstungsindustrie in Deutschl...</td>\n",
       "      <td>We want an armor industry in Germany</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129445.jpg</td>\n",
       "      <td>magier-jan-rouven.jpg</td>\n",
       "      <td>Deutscher Magier Jan Rouven in USA zu 20 Jahre...</td>\n",
       "      <td>German magician Jan Rouven sentenced to 20 yea...</td>\n",
       "      <td>Jan Rouven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>133721.jpg</td>\n",
       "      <td>bild-lei-containeruferstrasse-280319.jpg</td>\n",
       "      <td>Neue Gruppen in Containern</td>\n",
       "      <td>New groups in containers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>133722.jpg</td>\n",
       "      <td>bild-bahnhofstrasse-leichlingen.jpg</td>\n",
       "      <td>Fahrbahnsanierung der Bahnhofstraße beginnt</td>\n",
       "      <td>Road renovation of the Bahnhofstraße begins</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>133726.jpg</td>\n",
       "      <td>urn-newsml-dpa-com-20090101-190328-99-579319-l...</td>\n",
       "      <td>Schwebebahn startet nach Unfall wieder Testfah...</td>\n",
       "      <td>Swabbahn starts test drives after accident</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>133727.jpg</td>\n",
       "      <td>5f9cf8003ab339b0.jpg</td>\n",
       "      <td>Kein Ende der Krise bei Bayer in Sicht</td>\n",
       "      <td>No end of the crisis at Bayer in sight</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>133730.jpg</td>\n",
       "      <td>neuer-inhalt--2-.jpg</td>\n",
       "      <td>Unfall am Südbahnhof - Linie 9 wird umgeleitet</td>\n",
       "      <td>Accident on the South Station - Line 9 is redi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      129437.jpg                   dpa-polizist-vor-polizeiauto.jpg  \\\n",
       "0     129439.jpg                                  ali-t--280219.jpg   \n",
       "1     129440.jpg                                    kita-symbol.jpg   \n",
       "2     129442.jpg             bahnsteig-station-dom-hauptbahnhof.jpg   \n",
       "3     129443.jpg                  annegret-kramp-karrenbaur-cdu.jpg   \n",
       "4     129445.jpg                              magier-jan-rouven.jpg   \n",
       "...          ...                                                ...   \n",
       "2381  133721.jpg           bild-lei-containeruferstrasse-280319.jpg   \n",
       "2382  133722.jpg                bild-bahnhofstrasse-leichlingen.jpg   \n",
       "2383  133726.jpg  urn-newsml-dpa-com-20090101-190328-99-579319-l...   \n",
       "2384  133727.jpg                               5f9cf8003ab339b0.jpg   \n",
       "2385  133730.jpg                               neuer-inhalt--2-.jpg   \n",
       "\n",
       "     Polizei-Azubi erschießt mutmaßlich Mit-Auszubildenden  \\\n",
       "0     Hauptverdächtiger in Türkei gefasst – und wied...      \n",
       "1     Rhein-Erft-Kreis stoppt Kita-Bonus für städtis...      \n",
       "2     KVB-Fahrgastzahlen sind Grund zur Freude und S...      \n",
       "3     „Wir wollen eine Rüstungsindustrie in Deutschl...      \n",
       "4     Deutscher Magier Jan Rouven in USA zu 20 Jahre...      \n",
       "...                                                 ...      \n",
       "2381                         Neue Gruppen in Containern      \n",
       "2382        Fahrbahnsanierung der Bahnhofstraße beginnt      \n",
       "2383  Schwebebahn startet nach Unfall wieder Testfah...      \n",
       "2384             Kein Ende der Krise bei Bayer in Sicht      \n",
       "2385     Unfall am Südbahnhof - Linie 9 wird umgeleitet      \n",
       "\n",
       "           Police Azubi shoots alleged with-apprentices              \n",
       "0           Main suspect in Turkey - and released again              \n",
       "1     Rhine-Erft-Kreis Stops Kita bonus for urban em...        Kita  \n",
       "2     KVB passenger numbers are reason for joy and c...              \n",
       "3                  We want an armor industry in Germany              \n",
       "4     German magician Jan Rouven sentenced to 20 yea...  Jan Rouven  \n",
       "...                                                 ...         ...  \n",
       "2381                           New groups in containers              \n",
       "2382        Road renovation of the Bahnhofstraße begins              \n",
       "2383         Swabbahn starts test drives after accident              \n",
       "2384             No end of the crisis at Bayer in sight              \n",
       "2385  Accident on the South Station - Line 9 is redi...              \n",
       "\n",
       "[2386 rows x 5 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "22fb3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def comb_title_eng_text (orig_file, title_eng_file, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    texts=open(title_eng_file, 'r', encoding=\"utf-8\")\n",
    "    next(texts)\n",
    "    lines = [line.strip() for line in open(orig_file, 'r', encoding=\"utf-8\")]\n",
    "    texts_eng = [line.strip() for line in texts]\n",
    "    header=\"img_id\"+\"\\t\"+\"img_name\"+\"\\t\"+\"title\"+\"\\t\"+\"title_eng\"+\"\\t\"+\"title_names\"+\"\\t\"+\"text_eng\"+\"\\n\"\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        the_file.write(header)\n",
    "        for i in range(len(lines)):\n",
    "            text_eng=texts_eng[i].rstrip(\"\\n\")\n",
    "            orig_line=lines[i]\n",
    "            if len(orig_line.split(\"\\t\"))!=5:\n",
    "                orig_line+=\"\\t\"+\"NA\"\n",
    "            the_file.write(orig_line+\"\\t\"+text_eng+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e410381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng_text(\"title_01_title_eng_name.tsv\", \"trans_text_01_tr.txt\", 'title_01_title_eng_name_text_1.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2b0bfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng_text(\"title_02_title_eng_name.tsv\", \"trans_text_02_tr.txt\", 'title_02_title_eng_name_text.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "13646474",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng_text(\"title_03_title_eng_name.tsv\", \"trans_text_03_tr.txt\", 'title_03_title_eng_name_text.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng_text(\"title_03_title_eng_name.tsv\", \"trans_text_03_tr.txt\", 'title_03_title_eng_name_text.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f1cc13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_name(tr_file, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    a_file = open(tr_file, encoding=\"utf8\")\n",
    "    next(a_file)\n",
    "    cnt=0\n",
    "    name_list=[]\n",
    "    header=\"img_id\"+\"\\t\"+\"img_name\"+\"\\t\"+\"title\"+\"\\t\"+\"title_eng\"+\"\\t\"+\"title_names\"+\"\\t\"+\"text_eng\"+\"\\t\"+\"text_names\"+\"\\n\"\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        the_file.write(header)\n",
    "        for line in a_file:\n",
    "            title_eng=line.split(\"\\t\")[5]\n",
    "            tokenized_text = word_tokenize(title_eng)\n",
    "            classified_text = st.tag(tokenized_text)\n",
    "            names=concat_name(classified_text)\n",
    "            if len(names)>0:\n",
    "                names_str = ','.join(names)\n",
    "                print(names_str)\n",
    "                new_line=line.strip(\"\\n\")+\"\\t\"+names_str+\"\\n\"\n",
    "                cnt+=1\n",
    "            else:\n",
    "                new_line=line.strip(\"\\n\")+\"\\t \"+\"\\n\"\n",
    "            the_file.write(new_line)\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e441eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_text_name('title_01_title_eng_name_text_1.tsv', 'final_01.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2472a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "def create_name_folder (name_file):\n",
    "    a_file = open(name_file, encoding=\"utf8\")\n",
    "    next(a_file)\n",
    "    for line in a_file:\n",
    "        line=line.strip(\"\\n\")\n",
    "        img_name=line.split(\"\\t\")[0]\n",
    "        names=line.split(\"\\t\")[4].rstrip()\n",
    "        if len(names)>0:\n",
    "            path=os.path.join(\"faces\", names.split(\",\")[0])\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            copyfile(os.path.join(\"train_img\",img_name) , os.path.join(path,img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2fc85179",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_name_folder(\"title_01_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0eae5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_name_folder(\"title_02_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6e352ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_name_folder(\"title_03_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c60025a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>iid</th>\n",
       "      <th>imgFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ksta.de/image/23526828/2x1/300/150...</td>\n",
       "      <td>134801.0</td>\n",
       "      <td>23526828a8202ba73ce31c14cd42b066452c2f8SR.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ksta.de/image/23575686/2x1/300/150...</td>\n",
       "      <td>136751.0</td>\n",
       "      <td>23575686742e1a5e86aa6f2f919ea19f3fe10d54Rh.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ksta.de/image/23575776/2x1/300/150...</td>\n",
       "      <td>135527.0</td>\n",
       "      <td>2357577628a56ed4968b8c369921ebb39b271d4dEs.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ksta.de/image/23575790/2x1/300/150...</td>\n",
       "      <td>135908.0</td>\n",
       "      <td>23575790cb42cc1a43b7d8996d4c5b6f586185b8aj.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ksta.de/image/23575818/2x1/300/150...</td>\n",
       "      <td>135583.0</td>\n",
       "      <td>23575818c61b4d0961b6e0bb2798b78fbd901885qb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>https://www.ksta.de/image/32435912/2x1/300/150...</td>\n",
       "      <td>136928.0</td>\n",
       "      <td>324359122cc0aff2a1eb75cff09f948d63fcdf6ezg.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>https://www.ksta.de/image/32436164/2x1/300/150...</td>\n",
       "      <td>136931.0</td>\n",
       "      <td>32436164c26ad3a09ab4604cde6a60df95ae0ca3AG.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>https://www.ksta.de/image/32436674/2x1/300/150...</td>\n",
       "      <td>136958.0</td>\n",
       "      <td>32436674531b23b9bf5b73d1ada08a89c218bf82zA.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>https://www.ksta.de/image/32437042/2x1/300/150...</td>\n",
       "      <td>136941.0</td>\n",
       "      <td>32437042a64866cc07ab616bc74dd6a741b7eb19Vn.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1916 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    img       iid  \\\n",
       "0     https://www.ksta.de/image/23526828/2x1/300/150...  134801.0   \n",
       "1     https://www.ksta.de/image/23575686/2x1/300/150...  136751.0   \n",
       "2     https://www.ksta.de/image/23575776/2x1/300/150...  135527.0   \n",
       "3     https://www.ksta.de/image/23575790/2x1/300/150...  135908.0   \n",
       "4     https://www.ksta.de/image/23575818/2x1/300/150...  135583.0   \n",
       "...                                                 ...       ...   \n",
       "1911  https://www.ksta.de/image/32435912/2x1/300/150...  136928.0   \n",
       "1912  https://www.ksta.de/image/32436164/2x1/300/150...  136931.0   \n",
       "1913  https://www.ksta.de/image/32436674/2x1/300/150...  136958.0   \n",
       "1914  https://www.ksta.de/image/32437042/2x1/300/150...  136941.0   \n",
       "1915                                                NaN       NaN   \n",
       "\n",
       "                                             imgFile  \n",
       "0      23526828a8202ba73ce31c14cd42b066452c2f8SR.jpg  \n",
       "1     23575686742e1a5e86aa6f2f919ea19f3fe10d54Rh.jpg  \n",
       "2     2357577628a56ed4968b8c369921ebb39b271d4dEs.jpg  \n",
       "3     23575790cb42cc1a43b7d8996d4c5b6f586185b8aj.jpg  \n",
       "4     23575818c61b4d0961b6e0bb2798b78fbd901885qb.jpg  \n",
       "...                                              ...  \n",
       "1911  324359122cc0aff2a1eb75cff09f948d63fcdf6ezg.jpg  \n",
       "1912  32436164c26ad3a09ab4604cde6a60df95ae0ca3AG.jpg  \n",
       "1913  32436674531b23b9bf5b73d1ada08a89c218bf82zA.jpg  \n",
       "1914  32437042a64866cc07ab616bc74dd6a741b7eb19Vn.jpg  \n",
       "1915                                             NaN  \n",
       "\n",
       "[1916 rows x 3 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\yuxia\\Documents\\CS7311_Project\\FIREWHEEL\\data\\MediaEvalNewsImagesBatch04images.tsv\", delimiter=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a723d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests  # to get image from the web\n",
    "import shutil\n",
    "\n",
    "f = open(os.path.join(r'C:\\Users\\yuxia\\Documents\\CS7311_Project\\FIREWHEEL\\data',\"MediaEvalNewsImagesBatch04images.tsv\"), \"r\",encoding=\"utf-8\")\n",
    "next(f)\n",
    "for line in f:\n",
    "    image_url = line.split(\"\\t\")[0]\n",
    "    image_id=line.split(\"\\t\")[1]\n",
    "    filename = os.path.join('test_img',image_id+\".jpg\")\n",
    "    r = requests.get(image_url, stream=True,headers={'User-agent': 'Mozilla/5.0'})\n",
    "    if r.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        print(\"img can't be loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8c7af357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>aid</th>\n",
       "      <th>url</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>hashvalue</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>nImpressions</th>\n",
       "      <th>nRecs</th>\n",
       "      <th>nClicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000265e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/panorama/mit-kopfschuss-tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trainspotting-Star auf offener Straße erschossen</td>\n",
       "      <td>In Schottland haben Unbekannte den Schauspiele...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.001935e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/koeln/verspaetungen-und-au...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-Bahn-Gleis am Kölner Hauptbahnhof ist gesperrt</td>\n",
       "      <td>Der S-Bahn-Bahnsteig am Kölner Hauptbahnhof is...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002375e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/koeln/muelheim/zwei-kilo-m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drogendealer in Mülheim auf frischer Tat ertappt</td>\n",
       "      <td>Die Polizei hat einen einen 22-jährigen Drogen...</td>\n",
       "      <td>437.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.002735e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/koeln/fruehlingsvolksfest-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Die ungewöhnliche Ostermesse auf dem Autoscooter</td>\n",
       "      <td>Mit fast 33 Metern Höhe, einer Streckenlänge v...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.002835e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/region/rhein-erft/bergheim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Polizei fasst flüchtende Einbrecher nach 40 Se...</td>\n",
       "      <td>Das war ein kurzer Ausflug für zwei Einbrecher...</td>\n",
       "      <td>394.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>1.999165e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/sport/fussball/auch-hambur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB Leipzig gewinnt dramatischen Pokalfight in ...</td>\n",
       "      <td>RB Leipzig darf dank Marcel Halstenberg weiter...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>1.999345e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/panorama/berliner-eisbaerc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berliner Eisbärchen heißt Hertha</td>\n",
       "      <td>Begeisterung für Bälle hat sie schon gezeigt: ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>1.999355e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/politik/rnd/nach-moorbrand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bund zahlt 600.000 Euro Schadensersatz</td>\n",
       "      <td>Für Schäden nach einem Moorbrand auf dem Gelän...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>1.999735e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ksta.de/region/rwe-stoppt-boaplus-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Kohlekraftwerke haben keinen Platz in Zukunfs...</td>\n",
       "      <td>Der Energiekonzern RWE hat die Planungen zum B...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1916 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         articleID  aid                                                url  \\\n",
       "0     1.000265e+09  NaN  https://www.ksta.de/panorama/mit-kopfschuss-tr...   \n",
       "1     1.001935e+09  NaN  https://www.ksta.de/koeln/verspaetungen-und-au...   \n",
       "2     1.002375e+09  NaN  https://www.ksta.de/koeln/muelheim/zwei-kilo-m...   \n",
       "3     1.002735e+09  NaN  https://www.ksta.de/koeln/fruehlingsvolksfest-...   \n",
       "4     1.002835e+09  NaN  https://www.ksta.de/region/rhein-erft/bergheim...   \n",
       "...            ...  ...                                                ...   \n",
       "1911  1.999165e+09  NaN  https://www.ksta.de/sport/fussball/auch-hambur...   \n",
       "1912  1.999345e+09  NaN  https://www.ksta.de/panorama/berliner-eisbaerc...   \n",
       "1913  1.999355e+09  NaN  https://www.ksta.de/politik/rnd/nach-moorbrand...   \n",
       "1914  1.999735e+09  NaN  https://www.ksta.de/region/rwe-stoppt-boaplus-...   \n",
       "1915           NaN  NaN                                                NaN   \n",
       "\n",
       "      Unnamed: 3  Unnamed: 4  hashvalue  \\\n",
       "0            NaN         NaN        NaN   \n",
       "1            NaN         NaN        NaN   \n",
       "2            NaN         NaN        NaN   \n",
       "3            NaN         NaN        NaN   \n",
       "4            NaN         NaN        NaN   \n",
       "...          ...         ...        ...   \n",
       "1911         NaN         NaN        NaN   \n",
       "1912         NaN         NaN        NaN   \n",
       "1913         NaN         NaN        NaN   \n",
       "1914         NaN         NaN        NaN   \n",
       "1915         NaN         NaN        NaN   \n",
       "\n",
       "                                                  title  \\\n",
       "0      Trainspotting-Star auf offener Straße erschossen   \n",
       "1      S-Bahn-Gleis am Kölner Hauptbahnhof ist gesperrt   \n",
       "2      Drogendealer in Mülheim auf frischer Tat ertappt   \n",
       "3      Die ungewöhnliche Ostermesse auf dem Autoscooter   \n",
       "4     Polizei fasst flüchtende Einbrecher nach 40 Se...   \n",
       "...                                                 ...   \n",
       "1911  RB Leipzig gewinnt dramatischen Pokalfight in ...   \n",
       "1912                   Berliner Eisbärchen heißt Hertha   \n",
       "1913             Bund zahlt 600.000 Euro Schadensersatz   \n",
       "1914  „Kohlekraftwerke haben keinen Platz in Zukunfs...   \n",
       "1915                                                NaN   \n",
       "\n",
       "                                                   text  nImpressions  nRecs  \\\n",
       "0     In Schottland haben Unbekannte den Schauspiele...          13.0    0.0   \n",
       "1     Der S-Bahn-Bahnsteig am Kölner Hauptbahnhof is...          35.0    0.0   \n",
       "2     Die Polizei hat einen einen 22-jährigen Drogen...         437.0   25.0   \n",
       "3     Mit fast 33 Metern Höhe, einer Streckenlänge v...         178.0    0.0   \n",
       "4     Das war ein kurzer Ausflug für zwei Einbrecher...         394.0  543.0   \n",
       "...                                                 ...           ...    ...   \n",
       "1911  RB Leipzig darf dank Marcel Halstenberg weiter...           8.0    4.0   \n",
       "1912  Begeisterung für Bälle hat sie schon gezeigt: ...           6.0  642.0   \n",
       "1913  Für Schäden nach einem Moorbrand auf dem Gelän...           5.0  679.0   \n",
       "1914  Der Energiekonzern RWE hat die Planungen zum B...          12.0    0.0   \n",
       "1915                                                NaN           NaN    NaN   \n",
       "\n",
       "      nClicks  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         5.0  \n",
       "...       ...  \n",
       "1911      0.0  \n",
       "1912      2.0  \n",
       "1913      0.0  \n",
       "1914      0.0  \n",
       "1915      NaN  \n",
       "\n",
       "[1916 rows x 11 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\yuxia\\Documents\\CS7311_Project\\FIREWHEEL\\data\\MediaEvalNewsImagesBatch04articles.tsv\", delimiter=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "89123c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def extract_columns (orig_file, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    articles=open(orig_file, 'r', encoding=\"utf-8\")\n",
    "    next(articles)\n",
    "    lines = [line.strip() for line in articles]\n",
    "    header=\"article_id\"+\"\\t\"+\"title\"+\"\\n\"\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        the_file.write(header)\n",
    "        for i in range(len(lines)):\n",
    "            orig_line=lines[i]\n",
    "            segs = orig_line.split(\"\\t\")\n",
    "            print(len(segs))\n",
    "            print(segs)\n",
    "            the_file.write(segs[0]+\"\\t\"+segs[6]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_columns(r\"C:\\Users\\yuxia\\Documents\\CS7311_Project\\FIREWHEEL\\data\\MediaEvalNewsImagesBatch04articles.tsv\", \"test_orig.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d39dc2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_title_eng_test (orig_file, title_eng_file, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    lines = [line.strip() for line in open(orig_file, 'r', encoding=\"utf-8\")]\n",
    "    titles_eng = [line.strip() for line in open(title_eng_file, 'r', encoding=\"utf-8\")]\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        for i in range(len(lines)):\n",
    "            title_eng=titles_eng[i].rstrip(\"\\n\")\n",
    "            the_file.write(lines[i]+\"\\t\"+title_eng+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1dfb3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_title_eng_test(\"test_orig.tsv\", \"trans-test.txt\", \"test_title_eng.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "98994dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_title_name_text(tr_file, output_file):\n",
    "    a_file = open(tr_file, encoding=\"utf8\")\n",
    "    next(a_file)\n",
    "    cnt=0\n",
    "    name_list=[]\n",
    "    header=\"artitle_id\"+\"\\t\"+\"title_de\"+\"\\t\"+\"title_eng\"+\"\\t\"+\"title_names\"\n",
    "    with open(output_file, 'a',encoding=\"utf-8\") as the_file:\n",
    "        for line in a_file:\n",
    "            title_eng=line.split(\"\\t\")[2]\n",
    "            tokenized_text = word_tokenize(title_eng)\n",
    "            classified_text = st.tag(tokenized_text)\n",
    "            names=concat_name(classified_text)\n",
    "            if len(names)>0:\n",
    "                names_str = ','.join(names)\n",
    "                print(names_str)\n",
    "                new_line=line.strip(\"\\n\")+\"\\t\"+names_str+\"\\n\"\n",
    "                cnt+=1\n",
    "            else:\n",
    "                new_line=line.strip(\"\\n\")+\"\\t \"+\"NA\"+\"\\n\"\n",
    "            the_file.write(new_line)\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ee4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_title_name_text(\"test_title_eng.tsv\",\"test_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdf2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def extract_text (orig_file):\n",
    "    articles_names=open(orig_file, 'r', encoding=\"utf-8\")\n",
    "    next(articles_names)\n",
    "    lines = [line.strip() for line in articles_names]\n",
    "    result=[]\n",
    "    for i in range(len(lines)):\n",
    "        orig_line=lines[i]\n",
    "        segs = orig_line.split(\"\\t\")\n",
    "        result.append((segs[0], segs[3].split(\",\")[0]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0f7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_name_list=extract_text(\"test_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329a5e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1914"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d='faces'\n",
    "sub_directories = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "idx_name={}\n",
    "name_idx={}\n",
    "idx=1\n",
    "for sub_dir in sub_directories:\n",
    "    idx_name[sub_dir]='face_'+str(idx)\n",
    "    name_idx['face_'+str(idx)] = sub_dir\n",
    "    idx+=1\n",
    "name_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1198e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def copy_all_files(src, dest, idx_name):\n",
    "    src_files = os.listdir(src)\n",
    "    for file_name in src_files:\n",
    "        full_file_name = os.path.join(src, file_name)\n",
    "        dest_folder=os.path.join(dest, idx_name[os.path.basename(src)])\n",
    "        if not os.path.isdir(dest_folder):\n",
    "            os.mkdir(dest_folder)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768dae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "d='faces'\n",
    "sub_full_paths = [os.path.join(d, o) for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "sub_full_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f71367d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_folder='mapped_face'\n",
    "for sub_dir in sub_full_paths:\n",
    "    copy_all_files(sub_dir, mapped_folder, idx_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "cnt = 0\n",
    "img_files = [f for f in os.listdir(\"test_img\") if f.endswith('.jpg')]\n",
    "ar_img_files={}\n",
    "for ar_name in ar_name_list:\n",
    "    if ar_name[1].strip() != 'NA' and ar_name[1] in idx_name:\n",
    "        if os.path.exists(os.path.join(\"mapped_face\", idx_name[ar_name[1]])):\n",
    "            df_results=[]\n",
    "            for img_file in img_files:\n",
    "                img_path=os.path.join(\"test_img\", img_file)\n",
    "                df = DeepFace.find(img_path = img_path, db_path =os.path.join(\"mapped_face\", idx_name[ar_name[1]]), enforce_detection=False)\n",
    "                df_results.append(df)\n",
    "            ar_img_files[ar_name[0]]=df_results\n",
    "            print(len(df_results))\n",
    "            cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d3137a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0208ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar_img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "eca699d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1003715259'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ar_img_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1794f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "img_files = [f for f in os.listdir(\"test_img\") if f.endswith('.jpg')]\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "c=0\n",
    "for img_f in img_files:\n",
    "    try:\n",
    "        backends = ['ssd', 'mtcnn']\n",
    "        detected_face = DeepFace.detectFace(os.path.join('test_img',img_f), detector_backend = backends[0])\n",
    "        shutil.copy(os.path.join('test_img',img_f), \"test_img_face\")\n",
    "        c+=1\n",
    "    except Exception:\n",
    "        print(\"no face\")\n",
    "        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5de6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  faces\\Altmaier  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  1  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.4572765827178955  seconds\n"
     ]
    }
   ],
   "source": [
    "df_1 = DeepFace.find(img_path = r\"test_img_face\\134332.jpg\", db_path = r\"faces\\Altmaier\", model_name=\"VGG-Face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2639138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>VGG-Face_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faces\\Altmaier/124941.jpg</td>\n",
       "      <td>0.398045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    identity  VGG-Face_cosine\n",
       "0  faces\\Altmaier/124941.jpg         0.398045"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de1f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "def deep_detect(file):\n",
    "    c=0\n",
    "    for model in models:\n",
    "        try:\n",
    "            detected_face = DeepFace.detectFace(file, model_name=model)\n",
    "        except:\n",
    "            c+=1\n",
    "    if c== len(models):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fce58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "def detect_face_cv(file):\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    # Read the input image\n",
    "    img = cv2.imread(file)\n",
    "    width, height, channels=img.shape\n",
    "    # Convert into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces= face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw rectangle around the faces\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        if w!=width or height!=h:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"mapped_face\"\n",
    "sub_directories = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "c=0\n",
    "for sub_dir in sub_directories:\n",
    "    files = [os.path.join(sub_dir, f) for f in os.listdir(sub_dir) if f.endswith('.jpg')]\n",
    "    for file in files:\n",
    "        if not detect_face_cv(file) and not deep_detect(file):\n",
    "            shutil.copy(file, \"mapped_no_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0ff13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "path=\"mapped_face\"\n",
    "path_no_face=\"mapped_no_face\"\n",
    "sub_directories = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "files_no_face = [f for f in os.listdir(path_no_face) if f.endswith('.jpg')]\n",
    "c=0\n",
    "for sub_dir in sub_directories:\n",
    "    files = [f for f in os.listdir(sub_dir) if f.endswith('.jpg')]\n",
    "    for f in files:\n",
    "        if f in files_no_face:\n",
    "            shutil.move(os.path.join(sub_dir,f), \"mapped_face_removed\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc635b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_dir in sub_directories:\n",
    "    files = [f for f in os.listdir(sub_dir)]\n",
    "    if len(files)==0:\n",
    "        os.rmdir(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42123243",
   "metadata": {},
   "outputs": [],
   "source": [
    "d='faces'\n",
    "sub_directories = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "idx_name={}\n",
    "name_idx={}\n",
    "idx=1\n",
    "for sub_dir in sub_directories:\n",
    "    idx_name[sub_dir]='face_'+str(idx)\n",
    "    name_idx['face_'+str(idx)] = sub_dir\n",
    "    idx+=1\n",
    "name_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad67325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "img_files = [os.path.join('test_img',f) for f in os.listdir(\"test_img\") if f.endswith('.jpg')]\n",
    "c=0\n",
    "for img_f in img_files:\n",
    "    if  detect_face_cv(img_f) or deep_detect(img_f):\n",
    "        shutil.copy(img_f, \"test_img_face\")\n",
    "        c+=1\n",
    "    else:\n",
    "        print(\"no face\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4deb65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "def deep_detect_backend(file):\n",
    "    backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n",
    "    c=0\n",
    "    for backend in backends:\n",
    "        try:\n",
    "            detected_face = DeepFace.detectFace(file, detector_backend=backend)\n",
    "        except:\n",
    "            c+=1\n",
    "    if c== len(backends):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d43f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "img_files = [os.path.join('test_img',f) for f in os.listdir(\"test_img\") if f.endswith('.jpg')]\n",
    "c=0\n",
    "for img_f in img_files:\n",
    "    if  deep_detect_backend(img_f): \n",
    "        shutil.copy(img_f, \"test_img_face\")\n",
    "        c+=1\n",
    "    else:\n",
    "        print(\"no face\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5626b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"mapped_face\"\n",
    "sub_directories = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "c=0\n",
    "for sub_dir in sub_directories:\n",
    "    files = [os.path.join(sub_dir, f) for f in os.listdir(sub_dir) if f.endswith('.jpg')]\n",
    "    for file in files:\n",
    "        if not detect_face_cv(file) and not deep_detect(file) and not deep_detect_backend(file) :\n",
    "            shutil.copy(file, \"mapped_no_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03e32290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  faces\\Altmaier  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  1  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  1.3980741500854492  seconds\n"
     ]
    }
   ],
   "source": [
    "df_1 = DeepFace.find(img_path = r\"test_img_face\\134332.jpg\", db_path = r\"faces\\Altmaier\", model_name=models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec60bf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>VGG-Face_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faces\\Altmaier/124941.jpg</td>\n",
       "      <td>0.398045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    identity  VGG-Face_cosine\n",
       "0  faces\\Altmaier/124941.jpg         0.398045"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c795aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepface import DeepFace\n",
    "cnt = 0\n",
    "img_files = [f for f in os.listdir(\"test_img_face\") if f.endswith('.jpg')]\n",
    "ar_img_files={}\n",
    "for ar_name in ar_name_list:\n",
    "    if ar_name[1].strip() != 'NA' and ar_name[1] in idx_name:\n",
    "        if os.path.exists(os.path.join(\"mapped_face\", idx_name[ar_name[1]])):\n",
    "            df_results=[]\n",
    "            for img_file in img_files:\n",
    "                img_path=os.path.join(\"test_img_face\", img_file)\n",
    "                df = DeepFace.find(img_path = img_path, db_path =os.path.join(\"mapped_face\", idx_name[ar_name[1]]), model_name='Facenet', enforce_detection=False)\n",
    "                df_results.append((img_path,df))\n",
    "            ar_img_files[ar_name[0]]=df_results\n",
    "            cnt+=1\n",
    "            print(cnt, \" name completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ff712b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(ar_img_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
