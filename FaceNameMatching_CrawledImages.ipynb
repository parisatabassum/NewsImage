{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0599d81",
   "metadata": {},
   "source": [
    "### Face Similarity Caculation for crawled images\n",
    "- Loading the extracted name from txt file\n",
    "- If there are no paired images in the training dataset, we crawled image using google_crawler. The extracted person's name will be used as the keyword for image crawling.\n",
    "- Extract crawled face images paired with the extracted name\n",
    "- Caculate the face similarity between the face images in the test dataset and images paired with the extracted name in the crawled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8205f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def extract_text (orig_file):\n",
    "    articles_names=open(orig_file, 'r', encoding=\"utf-8\")\n",
    "    next(articles_names)\n",
    "    lines = [line.strip() for line in articles_names]\n",
    "    result=[]\n",
    "    for i in range(len(lines)):\n",
    "        orig_line=lines[i]\n",
    "        segs = orig_line.split(\"\\t\")\n",
    "        result.append((segs[0], segs[3].split(\",\")[0]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_name_list=extract_text(\"test_title_eng_name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ar_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40311ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "d='faces'\n",
    "sub_directories = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "idx_name={}\n",
    "name_idx={}\n",
    "idx=1\n",
    "for sub_dir in sub_directories:\n",
    "    idx_name[sub_dir]='face_'+str(idx)\n",
    "    name_idx['face_'+str(idx)] = sub_dir\n",
    "    idx+=1\n",
    "name_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7de0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icrawler\n",
    "from icrawler.builtin  import GoogleImageCrawler\n",
    "\n",
    "google_crawler = GoogleImageCrawler(feeder_threads=1,parser_threads=2,downloader_threads=4,storage={'root_dir': 'name_no_img'})\n",
    "filters = dict(date=((2019, 1, 1), (2020, 11, 30)))\n",
    "google_crawler.crawl(keyword='sunny', filters=filters, max_num=10, file_idx_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepface import DeepFace\n",
    "cnt = 0\n",
    "img_files = [f for f in os.listdir(\"test_img_face\") if f.endswith('.jpg')]\n",
    "ar_img_files={}\n",
    "f = open(\"name_no_img.txt\", \"a\")\n",
    "for ar_name in ar_name_list:\n",
    "    if ar_name[1].strip() != 'NA' and ar_name[1] in idx_name:\n",
    "        if os.path.exists(os.path.join(\"mapped_face\", idx_name[ar_name[1]])):\n",
    "            print(\"found\")\n",
    "    elif ar_name[1].strip() != 'NA':\n",
    "        if not os.path.isdir(os.path.join('name_no_img', ar_name[1])):\n",
    "            os.mkdir(os.path.join('name_no_img', ar_name[1]))\n",
    "        google_crawler = GoogleImageCrawler(feeder_threads=1,parser_threads=2,downloader_threads=4,storage={'root_dir': os.path.join('name_no_img', ar_name[1])})\n",
    "        filters = dict(date=((2019, 1, 1), (2021, 7, 30)))\n",
    "        google_crawler.crawl(keyword=ar_name[1], filters=filters, max_num=5, file_idx_offset=0)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "def detect_face_cv(file):\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    # Read the input image\n",
    "    img = cv2.imread(file)\n",
    "    width, height, channels=img.shape\n",
    "    # Convert into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces= face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw rectangle around the faces\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        if w!=width or height!=h:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9cf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "def deep_detect_backend(file):\n",
    "    backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n",
    "    c=0\n",
    "    for backend in backends:\n",
    "        try:\n",
    "            detected_face = DeepFace.detectFace(file, detector_backend=backend)\n",
    "        except:\n",
    "            c+=1\n",
    "    if c== len(backends):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cf378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "def deep_detect(file):\n",
    "    c=0\n",
    "    for model in models:\n",
    "        try:\n",
    "            detected_face = DeepFace.detectFace(file, model_name=model)\n",
    "        except:\n",
    "            c+=1\n",
    "    if c== len(models):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66121c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d='name_no_img'\n",
    "sub_directories = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "idx_name={}\n",
    "name_idx={}\n",
    "idx=1\n",
    "for sub_dir in sub_directories:\n",
    "    idx_name[sub_dir]='crawl_face_'+str(idx)\n",
    "    name_idx['crawl_face_'+str(idx)] = sub_dir\n",
    "    idx+=1\n",
    "name_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def copy_all_files(src, dest, idx_name):\n",
    "    src_files = os.listdir(src)\n",
    "    for file_name in src_files:\n",
    "        full_file_name = os.path.join(src, file_name)\n",
    "        dest_folder=os.path.join(dest, idx_name[os.path.basename(src)])\n",
    "        if not os.path.isdir(dest_folder):\n",
    "            os.mkdir(dest_folder)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2481fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d='name_no_img'\n",
    "sub_full_paths = [os.path.join(d, o) for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "sub_full_paths\n",
    "mapped_folder='crawl_mapped_face'\n",
    "for sub_dir in sub_full_paths:\n",
    "    copy_all_files(sub_dir, mapped_folder, idx_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path=\"crawl_mapped_face\"\n",
    "dest_folder=\"name_no_img_fp\"\n",
    "sub_directories = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "c=0\n",
    "for sub_dir in sub_directories:\n",
    "        files = [os.path.join(sub_dir, f) for f in os.listdir(sub_dir) if f.endswith('.jpg')]\n",
    "        for file in files:\n",
    "            if os.path.isdir(sub_dir) and not deep_detect_backend(file) and not deep_detect(file) and not detect_face_cv(file):\n",
    "                print(sub_dir)\n",
    "                shutil.rmtree(sub_dir) \n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DeepFace.find(img_path = r\"test_img_face\\139017.jpg\", db_path =r\"crawl_mapped_face\\crawl_face_4\", model_name='Facenet', enforce_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Facenet_cosine'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67975791",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepface import DeepFace\n",
    "cnt = 0\n",
    "img_files = [f for f in os.listdir(\"test_img_face\") if f.endswith('.jpg')]\n",
    "ar_img_files={}\n",
    "for ar_name in ar_name_list:\n",
    "    if ar_name[1].strip() != 'NA' and ar_name[1] in idx_name:\n",
    "        if os.path.exists(os.path.join(\"crawl_mapped_face\", idx_name[ar_name[1]])):\n",
    "            df_results=[]\n",
    "            for img_file in img_files:\n",
    "                img_path=os.path.join(\"test_img_face\", img_file)\n",
    "                df = DeepFace.find(img_path = img_path, db_path =os.path.join(\"crawl_mapped_face\", idx_name[ar_name[1]]), model_name='Facenet', enforce_detection=False)\n",
    "                if len(df)>0:\n",
    "                    df_results.append((img_path,df['Facenet_cosine'].mean(), len(df)))\n",
    "                else:\n",
    "                    df_results.append((img_path,\"NA\", 0))\n",
    "            ar_img_files[ar_name[0]]=df_results\n",
    "            cnt+=1\n",
    "            print(cnt, \" name completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7187739",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5338dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"crawl_img_similarity.txt\", \"a\")\n",
    "for key, v in ar_img_files.items():\n",
    "    for item in v:\n",
    "        result=key+\"\\t\"+os.path.basename(item[0])+\"\\t\"+str(item[1])+\"\\t\"+str(item[2])+\"\\n\"\n",
    "        f.write(result)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt') # if necessary...\n",
    "\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19688e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_caption (orig_file):\n",
    "    articles_names=open(orig_file, 'r', encoding=\"utf-8\")\n",
    "    lines = [line.strip() for line in articles_names]\n",
    "    result_dict={}\n",
    "    for i in range(len(lines)):\n",
    "        orig_line=lines[i]\n",
    "        segs = orig_line.split(\"\\t\")\n",
    "        if segs[0] not in result_dict:\n",
    "            result_dict[segs[0]]=segs[1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_dict=get_caption (\"test_img\\image_caption_result.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dafe3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_id_title (orig_file):\n",
    "    articles_names=open(orig_file, 'r', encoding=\"utf-8\")\n",
    "    next(articles_names)\n",
    "    lines = [line.strip() for line in articles_names]\n",
    "    result_dict={}\n",
    "    for i in range(len(lines)):\n",
    "        orig_line=lines[i]\n",
    "        segs = orig_line.split(\"\\t\")\n",
    "        if segs[0] not in result_dict:\n",
    "            result_dict[segs[0]]=segs[2]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64432c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_title=get_id_title (\"test_title_eng.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785adf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_result={}\n",
    "cnt=0\n",
    "for ar_id, title in id_title.items():\n",
    "    caption_sim=[]\n",
    "    for img_id, caption in caption_dict.items():\n",
    "        sim = cosine_sim(title, caption)\n",
    "        caption_sim.append((img_id, sim))\n",
    "    cnt+=1\n",
    "    print(cnt,\" article: \",ar_id)\n",
    "    sim_result[ar_id]=caption_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bbbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sim_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd51079",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"caption_similarity.txt\", \"a\")\n",
    "for key, v in sim_result.items():\n",
    "    for item in v:\n",
    "        result=key+\"\\t\"+os.path.basename(item[0])+\"\\t\"+str(item[1])+\"\\n\"\n",
    "        f.write(result)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_result_gen={}\n",
    "cnt=0\n",
    "for ar_id, title in id_title.items():\n",
    "    caption_sim=[]\n",
    "    for img_id, caption in caption_dict.items():\n",
    "        sim = cosine_sim(title, caption)\n",
    "        caption_sim.append((img_id, sim))\n",
    "    cnt+=1\n",
    "    print(cnt,\" article: \",ar_id)\n",
    "    sim_result_gen[ar_id]=caption_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for k, v in sim_result.items():\n",
    "    count = sum(value[1] == 0 for value in sim_result[k])\n",
    "    if count == 1913:\n",
    "        cnt+=1\n",
    "print(cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
